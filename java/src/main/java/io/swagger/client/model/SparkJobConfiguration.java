/*
 * Hopsworks api
 * No description provided (generated by Swagger Codegen https://github.com/swagger-api/swagger-codegen)
 *
 * OpenAPI spec version: 1.1.0-SNAPSHOT
 * 
 *
 * NOTE: This class is auto generated by the swagger code generator program.
 * https://github.com/swagger-api/swagger-codegen.git
 * Do not edit the class manually.
 */

package io.swagger.client.model;

import java.util.Objects;
import com.google.gson.TypeAdapter;
import com.google.gson.annotations.JsonAdapter;
import com.google.gson.annotations.SerializedName;
import com.google.gson.stream.JsonReader;
import com.google.gson.stream.JsonWriter;
import io.swagger.client.model.LocalResourceDTO;
import io.swagger.client.model.YarnJobConfiguration;
import io.swagger.v3.oas.annotations.media.Schema;
import java.io.IOException;
import java.util.List;

/**
 * SparkJobConfiguration
 */

@javax.annotation.Generated(value = "io.swagger.codegen.v3.generators.java.JavaClientCodegen", date = "2019-11-28T02:09:19.386+01:00[Europe/Stockholm]")public class SparkJobConfiguration extends YarnJobConfiguration {

  @SerializedName("appPath")
  private String appPath = null;

  @SerializedName("mainClass")
  private String mainClass = null;

  @SerializedName("args")
  private String args = null;

  @SerializedName("properties")
  private String properties = null;
  /**
   * Gets or Sets experimentType
   */
  @JsonAdapter(ExperimentTypeEnum.Adapter.class)
  public enum ExperimentTypeEnum {
    EXPERIMENT("EXPERIMENT"),
    PARALLEL_EXPERIMENTS("PARALLEL_EXPERIMENTS"),
    DISTRIBUTED_TRAINING("DISTRIBUTED_TRAINING");

    private String value;

    ExperimentTypeEnum(String value) {
      this.value = value;
    }
    public String getValue() {
      return value;
    }

    @Override
    public String toString() {
      return String.valueOf(value);
    }
    public static ExperimentTypeEnum fromValue(String text) {
      for (ExperimentTypeEnum b : ExperimentTypeEnum.values()) {
        if (String.valueOf(b.value).equals(text)) {
          return b;
        }
      }
      return null;
    }
    public static class Adapter extends TypeAdapter<ExperimentTypeEnum> {
      @Override
      public void write(final JsonWriter jsonWriter, final ExperimentTypeEnum enumeration) throws IOException {
        jsonWriter.value(enumeration.getValue());
      }

      @Override
      public ExperimentTypeEnum read(final JsonReader jsonReader) throws IOException {
        String value = jsonReader.nextString();
        return ExperimentTypeEnum.fromValue(String.valueOf(value));
      }
    }
  }
  @SerializedName("experimentType")
  private ExperimentTypeEnum experimentType = null;
  /**
   * Gets or Sets distributionStrategy
   */
  @JsonAdapter(DistributionStrategyEnum.Adapter.class)
  public enum DistributionStrategyEnum {
    MIRRORED("MIRRORED"),
    PARAMETER_SERVER("PARAMETER_SERVER"),
    COLLECTIVE_ALL_REDUCE("COLLECTIVE_ALL_REDUCE");

    private String value;

    DistributionStrategyEnum(String value) {
      this.value = value;
    }
    public String getValue() {
      return value;
    }

    @Override
    public String toString() {
      return String.valueOf(value);
    }
    public static DistributionStrategyEnum fromValue(String text) {
      for (DistributionStrategyEnum b : DistributionStrategyEnum.values()) {
        if (String.valueOf(b.value).equals(text)) {
          return b;
        }
      }
      return null;
    }
    public static class Adapter extends TypeAdapter<DistributionStrategyEnum> {
      @Override
      public void write(final JsonWriter jsonWriter, final DistributionStrategyEnum enumeration) throws IOException {
        jsonWriter.value(enumeration.getValue());
      }

      @Override
      public DistributionStrategyEnum read(final JsonReader jsonReader) throws IOException {
        String value = jsonReader.nextString();
        return DistributionStrategyEnum.fromValue(String.valueOf(value));
      }
    }
  }
  @SerializedName("distributionStrategy")
  private DistributionStrategyEnum distributionStrategy = null;

  @SerializedName("executorInstances")
  private Integer executorInstances = null;

  @SerializedName("executorCores")
  private Integer executorCores = null;

  @SerializedName("executorMemory")
  private Integer executorMemory = null;

  @SerializedName("executorGpus")
  private Integer executorGpus = null;

  @SerializedName("numPs")
  private Integer numPs = null;

  @SerializedName("dynamicAllocationEnabled")
  private Boolean dynamicAllocationEnabled = null;

  @SerializedName("dynamicAllocationMinExecutors")
  private Integer dynamicAllocationMinExecutors = null;

  @SerializedName("dynamicAllocationMaxExecutors")
  private Integer dynamicAllocationMaxExecutors = null;

  @SerializedName("dynamicAllocationInitialExecutors")
  private Integer dynamicAllocationInitialExecutors = null;

  @SerializedName("blacklistingEnabled")
  private Boolean blacklistingEnabled = null;

  @SerializedName("pyFiles")
  private String pyFiles = null;

  @SerializedName("files")
  private String files = null;

  @SerializedName("jars")
  private String jars = null;

  @SerializedName("archives")
  private String archives = null;
  public SparkJobConfiguration appPath(String appPath) {
    this.appPath = appPath;
    return this;
  }

  

  /**
  * Get appPath
  * @return appPath
  **/
  @Schema(description = "")
  public String getAppPath() {
    return appPath;
  }
  public void setAppPath(String appPath) {
    this.appPath = appPath;
  }
  public SparkJobConfiguration mainClass(String mainClass) {
    this.mainClass = mainClass;
    return this;
  }

  

  /**
  * Get mainClass
  * @return mainClass
  **/
  @Schema(description = "")
  public String getMainClass() {
    return mainClass;
  }
  public void setMainClass(String mainClass) {
    this.mainClass = mainClass;
  }
  public SparkJobConfiguration args(String args) {
    this.args = args;
    return this;
  }

  

  /**
  * Get args
  * @return args
  **/
  @Schema(description = "")
  public String getArgs() {
    return args;
  }
  public void setArgs(String args) {
    this.args = args;
  }
  public SparkJobConfiguration properties(String properties) {
    this.properties = properties;
    return this;
  }

  

  /**
  * Get properties
  * @return properties
  **/
  @Schema(description = "")
  public String getProperties() {
    return properties;
  }
  public void setProperties(String properties) {
    this.properties = properties;
  }
  public SparkJobConfiguration experimentType(ExperimentTypeEnum experimentType) {
    this.experimentType = experimentType;
    return this;
  }

  

  /**
  * Get experimentType
  * @return experimentType
  **/
  @Schema(description = "")
  public ExperimentTypeEnum getExperimentType() {
    return experimentType;
  }
  public void setExperimentType(ExperimentTypeEnum experimentType) {
    this.experimentType = experimentType;
  }
  public SparkJobConfiguration distributionStrategy(DistributionStrategyEnum distributionStrategy) {
    this.distributionStrategy = distributionStrategy;
    return this;
  }

  

  /**
  * Get distributionStrategy
  * @return distributionStrategy
  **/
  @Schema(description = "")
  public DistributionStrategyEnum getDistributionStrategy() {
    return distributionStrategy;
  }
  public void setDistributionStrategy(DistributionStrategyEnum distributionStrategy) {
    this.distributionStrategy = distributionStrategy;
  }
  public SparkJobConfiguration executorInstances(Integer executorInstances) {
    this.executorInstances = executorInstances;
    return this;
  }

  

  /**
  * Get executorInstances
  * @return executorInstances
  **/
  @Schema(description = "")
  public Integer getExecutorInstances() {
    return executorInstances;
  }
  public void setExecutorInstances(Integer executorInstances) {
    this.executorInstances = executorInstances;
  }
  public SparkJobConfiguration executorCores(Integer executorCores) {
    this.executorCores = executorCores;
    return this;
  }

  

  /**
  * Get executorCores
  * @return executorCores
  **/
  @Schema(description = "")
  public Integer getExecutorCores() {
    return executorCores;
  }
  public void setExecutorCores(Integer executorCores) {
    this.executorCores = executorCores;
  }
  public SparkJobConfiguration executorMemory(Integer executorMemory) {
    this.executorMemory = executorMemory;
    return this;
  }

  

  /**
  * Get executorMemory
  * @return executorMemory
  **/
  @Schema(description = "")
  public Integer getExecutorMemory() {
    return executorMemory;
  }
  public void setExecutorMemory(Integer executorMemory) {
    this.executorMemory = executorMemory;
  }
  public SparkJobConfiguration executorGpus(Integer executorGpus) {
    this.executorGpus = executorGpus;
    return this;
  }

  

  /**
  * Get executorGpus
  * @return executorGpus
  **/
  @Schema(description = "")
  public Integer getExecutorGpus() {
    return executorGpus;
  }
  public void setExecutorGpus(Integer executorGpus) {
    this.executorGpus = executorGpus;
  }
  public SparkJobConfiguration numPs(Integer numPs) {
    this.numPs = numPs;
    return this;
  }

  

  /**
  * Get numPs
  * @return numPs
  **/
  @Schema(description = "")
  public Integer getNumPs() {
    return numPs;
  }
  public void setNumPs(Integer numPs) {
    this.numPs = numPs;
  }
  public SparkJobConfiguration dynamicAllocationEnabled(Boolean dynamicAllocationEnabled) {
    this.dynamicAllocationEnabled = dynamicAllocationEnabled;
    return this;
  }

  

  /**
  * Get dynamicAllocationEnabled
  * @return dynamicAllocationEnabled
  **/
  @Schema(description = "")
  public Boolean isDynamicAllocationEnabled() {
    return dynamicAllocationEnabled;
  }
  public void setDynamicAllocationEnabled(Boolean dynamicAllocationEnabled) {
    this.dynamicAllocationEnabled = dynamicAllocationEnabled;
  }
  public SparkJobConfiguration dynamicAllocationMinExecutors(Integer dynamicAllocationMinExecutors) {
    this.dynamicAllocationMinExecutors = dynamicAllocationMinExecutors;
    return this;
  }

  

  /**
  * Get dynamicAllocationMinExecutors
  * @return dynamicAllocationMinExecutors
  **/
  @Schema(description = "")
  public Integer getDynamicAllocationMinExecutors() {
    return dynamicAllocationMinExecutors;
  }
  public void setDynamicAllocationMinExecutors(Integer dynamicAllocationMinExecutors) {
    this.dynamicAllocationMinExecutors = dynamicAllocationMinExecutors;
  }
  public SparkJobConfiguration dynamicAllocationMaxExecutors(Integer dynamicAllocationMaxExecutors) {
    this.dynamicAllocationMaxExecutors = dynamicAllocationMaxExecutors;
    return this;
  }

  

  /**
  * Get dynamicAllocationMaxExecutors
  * @return dynamicAllocationMaxExecutors
  **/
  @Schema(description = "")
  public Integer getDynamicAllocationMaxExecutors() {
    return dynamicAllocationMaxExecutors;
  }
  public void setDynamicAllocationMaxExecutors(Integer dynamicAllocationMaxExecutors) {
    this.dynamicAllocationMaxExecutors = dynamicAllocationMaxExecutors;
  }
  public SparkJobConfiguration dynamicAllocationInitialExecutors(Integer dynamicAllocationInitialExecutors) {
    this.dynamicAllocationInitialExecutors = dynamicAllocationInitialExecutors;
    return this;
  }

  

  /**
  * Get dynamicAllocationInitialExecutors
  * @return dynamicAllocationInitialExecutors
  **/
  @Schema(description = "")
  public Integer getDynamicAllocationInitialExecutors() {
    return dynamicAllocationInitialExecutors;
  }
  public void setDynamicAllocationInitialExecutors(Integer dynamicAllocationInitialExecutors) {
    this.dynamicAllocationInitialExecutors = dynamicAllocationInitialExecutors;
  }
  public SparkJobConfiguration blacklistingEnabled(Boolean blacklistingEnabled) {
    this.blacklistingEnabled = blacklistingEnabled;
    return this;
  }

  

  /**
  * Get blacklistingEnabled
  * @return blacklistingEnabled
  **/
  @Schema(description = "")
  public Boolean isBlacklistingEnabled() {
    return blacklistingEnabled;
  }
  public void setBlacklistingEnabled(Boolean blacklistingEnabled) {
    this.blacklistingEnabled = blacklistingEnabled;
  }
  public SparkJobConfiguration pyFiles(String pyFiles) {
    this.pyFiles = pyFiles;
    return this;
  }

  

  /**
  * Get pyFiles
  * @return pyFiles
  **/
  @Schema(description = "")
  public String getPyFiles() {
    return pyFiles;
  }
  public void setPyFiles(String pyFiles) {
    this.pyFiles = pyFiles;
  }
  public SparkJobConfiguration files(String files) {
    this.files = files;
    return this;
  }

  

  /**
  * Get files
  * @return files
  **/
  @Schema(description = "")
  public String getFiles() {
    return files;
  }
  public void setFiles(String files) {
    this.files = files;
  }
  public SparkJobConfiguration jars(String jars) {
    this.jars = jars;
    return this;
  }

  

  /**
  * Get jars
  * @return jars
  **/
  @Schema(description = "")
  public String getJars() {
    return jars;
  }
  public void setJars(String jars) {
    this.jars = jars;
  }
  public SparkJobConfiguration archives(String archives) {
    this.archives = archives;
    return this;
  }

  

  /**
  * Get archives
  * @return archives
  **/
  @Schema(description = "")
  public String getArchives() {
    return archives;
  }
  public void setArchives(String archives) {
    this.archives = archives;
  }
  @Override
  public boolean equals(java.lang.Object o) {
    if (this == o) {
      return true;
    }
    if (o == null || getClass() != o.getClass()) {
      return false;
    }
    SparkJobConfiguration sparkJobConfiguration = (SparkJobConfiguration) o;
    return Objects.equals(this.appPath, sparkJobConfiguration.appPath) &&
        Objects.equals(this.mainClass, sparkJobConfiguration.mainClass) &&
        Objects.equals(this.args, sparkJobConfiguration.args) &&
        Objects.equals(this.properties, sparkJobConfiguration.properties) &&
        Objects.equals(this.experimentType, sparkJobConfiguration.experimentType) &&
        Objects.equals(this.distributionStrategy, sparkJobConfiguration.distributionStrategy) &&
        Objects.equals(this.executorInstances, sparkJobConfiguration.executorInstances) &&
        Objects.equals(this.executorCores, sparkJobConfiguration.executorCores) &&
        Objects.equals(this.executorMemory, sparkJobConfiguration.executorMemory) &&
        Objects.equals(this.executorGpus, sparkJobConfiguration.executorGpus) &&
        Objects.equals(this.numPs, sparkJobConfiguration.numPs) &&
        Objects.equals(this.dynamicAllocationEnabled, sparkJobConfiguration.dynamicAllocationEnabled) &&
        Objects.equals(this.dynamicAllocationMinExecutors, sparkJobConfiguration.dynamicAllocationMinExecutors) &&
        Objects.equals(this.dynamicAllocationMaxExecutors, sparkJobConfiguration.dynamicAllocationMaxExecutors) &&
        Objects.equals(this.dynamicAllocationInitialExecutors, sparkJobConfiguration.dynamicAllocationInitialExecutors) &&
        Objects.equals(this.blacklistingEnabled, sparkJobConfiguration.blacklistingEnabled) &&
        Objects.equals(this.pyFiles, sparkJobConfiguration.pyFiles) &&
        Objects.equals(this.files, sparkJobConfiguration.files) &&
        Objects.equals(this.jars, sparkJobConfiguration.jars) &&
        Objects.equals(this.archives, sparkJobConfiguration.archives) &&
        super.equals(o);
  }

  @Override
  public int hashCode() {
    return java.util.Objects.hash(appPath, mainClass, args, properties, experimentType, distributionStrategy, executorInstances, executorCores, executorMemory, executorGpus, numPs, dynamicAllocationEnabled, dynamicAllocationMinExecutors, dynamicAllocationMaxExecutors, dynamicAllocationInitialExecutors, blacklistingEnabled, pyFiles, files, jars, archives, super.hashCode());
  }

  @Override
  public String toString() {
    StringBuilder sb = new StringBuilder();
    sb.append("class SparkJobConfiguration {\n");
    sb.append("    ").append(toIndentedString(super.toString())).append("\n");
    sb.append("    appPath: ").append(toIndentedString(appPath)).append("\n");
    sb.append("    mainClass: ").append(toIndentedString(mainClass)).append("\n");
    sb.append("    args: ").append(toIndentedString(args)).append("\n");
    sb.append("    properties: ").append(toIndentedString(properties)).append("\n");
    sb.append("    experimentType: ").append(toIndentedString(experimentType)).append("\n");
    sb.append("    distributionStrategy: ").append(toIndentedString(distributionStrategy)).append("\n");
    sb.append("    executorInstances: ").append(toIndentedString(executorInstances)).append("\n");
    sb.append("    executorCores: ").append(toIndentedString(executorCores)).append("\n");
    sb.append("    executorMemory: ").append(toIndentedString(executorMemory)).append("\n");
    sb.append("    executorGpus: ").append(toIndentedString(executorGpus)).append("\n");
    sb.append("    numPs: ").append(toIndentedString(numPs)).append("\n");
    sb.append("    dynamicAllocationEnabled: ").append(toIndentedString(dynamicAllocationEnabled)).append("\n");
    sb.append("    dynamicAllocationMinExecutors: ").append(toIndentedString(dynamicAllocationMinExecutors)).append("\n");
    sb.append("    dynamicAllocationMaxExecutors: ").append(toIndentedString(dynamicAllocationMaxExecutors)).append("\n");
    sb.append("    dynamicAllocationInitialExecutors: ").append(toIndentedString(dynamicAllocationInitialExecutors)).append("\n");
    sb.append("    blacklistingEnabled: ").append(toIndentedString(blacklistingEnabled)).append("\n");
    sb.append("    pyFiles: ").append(toIndentedString(pyFiles)).append("\n");
    sb.append("    files: ").append(toIndentedString(files)).append("\n");
    sb.append("    jars: ").append(toIndentedString(jars)).append("\n");
    sb.append("    archives: ").append(toIndentedString(archives)).append("\n");
    sb.append("}");
    return sb.toString();
  }

  /**
   * Convert the given object to string with each line indented by 4 spaces
   * (except the first line).
   */
  private String toIndentedString(java.lang.Object o) {
    if (o == null) {
      return "null";
    }
    return o.toString().replace("\n", "\n    ");
  }

}
